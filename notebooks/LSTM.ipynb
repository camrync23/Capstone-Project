{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a908ccad-4bcf-404d-ae15-23373cb50a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e89e74c8-ed7e-4797-a660-ba079d96d6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_parquet('../data/cleaned_data_snappy.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4d53e25-40c4-4ab8-b9c1-e63aee650132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample: Take 1 million rows for faster training\n",
    "df_sample = df.sample(n=1000000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1840e640-1490-42c9-9e5e-d8e838302654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-transform target variable if right-skewed\n",
    "df_sample['totalFare'] = np.log1p(df_sample['totalFare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "572f9a17-aace-4650-a37d-da34516dfa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by `daysToDeparture` instead of `flightDate`\n",
    "df_sample = df_sample.sort_values(by=['daysToDeparture'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77fd385a-fe80-429e-a4f5-d78436c693a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure `durationToDistanceRatio` exists\n",
    "if 'durationToDistanceRatio' not in df_sample.columns:\n",
    "    df_sample['durationToDistanceRatio'] = df_sample['totalAirtime'] / df_sample['totalTravelDistance']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9bc4cbc-ec81-499f-a02e-80da7ace83d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace infinite values and drop NaNs\n",
    "df_sample['durationToDistanceRatio'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df_sample.dropna(subset=['durationToDistanceRatio'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a92c24e-ef6c-4bae-a071-0d42715d6247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features based on EDA insights\n",
    "features = ['daysToDeparture', 'pricePerMile', 'isHoliday', 'preHolidayFlight', \n",
    "            'postHolidayFlight', 'totalLayoverTime', 'durationToDistanceRatio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c48ff04a-5231-4ec2-8322-286b77fdcb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lag features based on `daysToDeparture`\n",
    "df_sample['fareLag_1'] = df_sample['totalFare'].shift(1)\n",
    "df_sample['fareLag_7'] = df_sample['totalFare'].shift(7)\n",
    "features += ['fareLag_1', 'fareLag_7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ad5d743-f876-4bbc-9a87-b2342a288553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaNs created by lag features\n",
    "df_sample.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef80c8da-9eb4-4703-9298-e0ef552ba36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "X = df_sample[features]\n",
    "y = df_sample['totalFare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "197c3ca9-1e72-4fd8-89b1-add703191c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize numerical data using Min-Max Scaling (needed for LSTM)\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1873504f-7276-4315-882c-0f977e204311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays for LSTM processing\n",
    "X_array = np.array(X_scaled)\n",
    "y_array = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d4f98d8-4605-40ac-a08b-cb3d56419a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape for LSTM (samples, time steps, features)\n",
    "X_lstm = np.reshape(X_array, (X_array.shape[0], 1, X_array.shape[1]))  # 1 time step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec1d5c80-894d-4958-8289-0f61807087cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split (80% Train, 10% Validation, 10% Test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_lstm, y_array, test_size=0.2, shuffle=False)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa63b796-030b-4987-8269-2cff1136fa07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Allison Conrey\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build LSTM Model\n",
    "model = Sequential([\n",
    "    LSTM(50, return_sequences=True, stateful=False, input_shape=(1, X_lstm.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    LSTM(50, return_sequences=False, stateful=False),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Dense(25, activation='relu'),\n",
    "    Dense(1)  # Output Layer\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1324ba0c-d46c-425d-95e3-e867a8b0fb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec2e0bfb-c339-4e54-a5ff-f8d0a3e44e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model with Early Stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec39d18-15f7-4c99-bfb9-57d0db0fa36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m25000/25000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 4ms/step - loss: 0.8393 - mae: 0.4218 - val_loss: 0.0142 - val_mae: 0.0889\n",
      "Epoch 2/20\n",
      "\u001b[1m25000/25000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3ms/step - loss: 0.0247 - mae: 0.1218 - val_loss: 0.0213 - val_mae: 0.1169\n",
      "Epoch 3/20\n",
      "\u001b[1m15269/25000\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 3ms/step - loss: 0.0216 - mae: 0.1136"
     ]
    }
   ],
   "source": [
    "# Reduce batch size for memory efficiency (32 instead of 64)\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), \n",
    "                    epochs=20, batch_size=32, callbacks=[early_stop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dc644a-7b17-4c83-8fc6-9ce7a415909c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model on Test Data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_real = np.expm1(y_pred)  # Convert back from log scale\n",
    "y_test_real = np.expm1(y_test)  # Convert back from log scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1b0c0b-6a36-45d1-83f8-2e7b166a6792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Evaluation Metrics\n",
    "mae = mean_absolute_error(y_test_real, y_pred_real)\n",
    "r2 = r2_score(y_test_real, y_pred_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cab182-7e77-4ff1-9f25-41727e7c772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Test MAE: {mae:.4f}\")\n",
    "print(f\"Test R² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00df6d1-4875-4696-ac20-f74d53c92b84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
